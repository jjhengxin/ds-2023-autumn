沙龙回顾 | 数据科学与工程研究生学术沙龙（第29期）大语言模型时代：应用与挑战
DaSE@ECNU 华东师范大学数据学院 2023-11-28 11:06 发表于上海
活动背景 BACKGROUND

近来，大型语言模型（LLM）在学术和工业领域引起了广泛关注，其强大的语言生成和理解能力为各个领域带来了新的机遇。研究人员和工业界纷纷探索如何充分利用LLM的潜力，以解决复杂的问题并推动创新。在学术领域，LLM被广泛应用于自然语言处理、信息检索、知识图谱等任务，取得了显著的成果。本次学术沙龙以“The Era of Large Language Models: Applications and Challenges”为主题，探讨了以下问题：（1）应用：LLM目前应用在哪些方面，具有哪些限制？（2） 挑战：还有哪些问题尚未解决？

活动回顾 REVIEW

第29期研究生学术沙龙于2023年11月24日在线下如期举行，许多同学和老师来到现场进行交流学习。沙龙由兰韵诗副教授主持，以“The Era of Large Language Models: Applications and Challenges”为主题，来自上海交通大学的林洲汉助理教授首先介绍了关于大语言模型的人类可读的指纹技术。然后，我院博士研究生梁远远、韩程程、王宇分别针对知识图谱辅助LLM做自然语言生成、对话式CoT提升小模型的推理能力、代码注释生成进行了精彩的分享。

林洲汉

HuRef: HUman-REadable 

Fingerprint for Large 

Language Models

在本次报告中，上海交通大学的林洲汉助理教授介绍了关于大语言模型的人类可读的指纹技术。目前，许多开源的大语言模型（例如LLaMA、ChatGLM等）的使用都需要进行许可证申请，或者不允许将其商用。由于大型语言模型（LLM）的资源密集型训练和精心设计的许可证，保护其版权变得至关重要。然而，通过微调或持续预训练可能会改变LLM的参数，识别LLM的原始基础模型具有挑战性。研究的动机源于通过指纹可以识别某个人，即使其他信息改变，指纹信息也是不变的。因此，是否可以为LLM定制一套指纹系统，基于指纹和不变项保护LLM而不泄露模型参数呢


基于此，林洲汉助理教授介绍了他们团队研发的HuRef技术，这是一种LLM的人类可读指纹，可以唯一地识别基本模型，而不会暴露模型参数或干扰训练。首先，他们观察到在预训练过程中，模型收敛后，LLM参数的矢量方向保持稳定。例如，LLaMA的子代模型与LLaMA-7B基本模型相比保持较高的参数余弦相似性，而独立预训练的LLM与LLaMA-7B模型显示出几乎零余弦相似性。因此，可以通过计算LLM参数向量的余弦相似性来识别它们的基本模型。同时，研究发现在不损害基础模型能力的情况下，很难偏离模型参数的矢量方向。然而，模型参数的矢量方向在受到一些即使简单的攻击后，如维度排列或矩阵旋转，也会在不影响性能的情况下显著改变。为了解决这个问题，利用Transformer结构，他们系统地分析了潜在的攻击，并定义了三个不变项来识别LLM的基本模型。直接将LLM的不变项作为指纹可能不直观，需要额外的计算来比较其与其他LLM的相似性，因此，他们以狗图像的形式作为LLM的身份指纹，其中狗的外观可以直接表示LLM的基本模型。各种LLM的实验结果证明了该方法的有效性，生成的狗图像对不同的训练步骤保持不变。最后，林洲汉助理教授对该方法的限制进行了介绍。



梁远远

Knowledge Graph assists 

LLM in Natural Language 

Generation
在本次报告中，梁远远主要探讨了知识图谱（KG）在辅助大语言模型（LLM）执行自然语言生成（NLG）任务方面的应用。报告分为三个部分，第一部分首先简要介绍了KG和LLM的幻觉现象。KG通过三元组（头实体，关系，尾实体）表示知识，包括百科KG、常识KG、领域KG和多模态KG。通过问答示例阐释了LLM的固有难题，即幻觉现象，无法完全消除，只能通过额外知识缓解。通过对比图形象描述了LLM和KG作为知识存储载体的优缺点，并探讨了KG辅助LLM在NLG任务中的可能性。
第二部分梁远远介绍了一种结合LLM和CoT的技术，以弥补基于知识库的问答（KBQG）任务在少样本情况下的不足。KBQG旨在将结构化逻辑形式转换为自然语言问题，由于标注成本高，不适用于少量数据生成，因此迫切需要低资源场景下的解决方案。随着LLMs+CoT的出现，提出了一种新的提示方法KQG-CoT：首先，考虑逻辑形式的结构特征，从未标记的数据池中选择支持的逻辑形式。其次，构建任务特定的提示，引导LLMs生成基于选择性逻辑形式的复杂问题。此外，通过对逻辑形式的复杂性进行排序，KQG-CoT扩展为KQG-CoT+。在三个公共KBQG数据集上进行的广泛实验取得了显著效果，证明了该方法的有效性。
第三部分梁远远介绍了KG辅助LLM执行Text2Cypher任务，首先定义了Text2Cypher任务，即给定一个KG和问题，生成能在KG上执行查询的语句。然后，对比了Text2Cypher和Text2Sql的差异，介绍了Text2Cypher研究领域的现状，并探讨了一个正在进行的金融领域的Text2Cypher数据集。最后，鼓励大家在这个领域进行深入探索，开拓Text2Cypher的新领域。
韩程程

DialCoT Meets PPO: 

Decomposing and Exploring 

Reasoning Paths in Smaller 

Language Models
本次报告中，韩程程首先回顾了用于提升大模型推理能力的思维链（CoT, Chain-of-Thought）技术。思维链技术通过仿照一个人在思考问题或解决问题时所形成的一系列相互关联的思维过程，提示大模型将问题拆分并执行多步推理，提升LLM的推理能力。但是，从多篇论文的实验结果中可以看出，思维链技术仅在60B以上的大模型上有效果，在10B左右的大模型上几乎没有效果，甚至有一些副作用。但10B左右的大模型是我们目前部署最广泛的模型，因此如何提升10B左右模型的推理能力是非常重要的研究课题，同时也面临着巨大的挑战。
随后，韩程程介绍了他们团队最新发表在EMNLP2023上的工作《DialCoT meets PPO: Decomposing and Exploring Reasoning Path in Smaller Language Models》，该工作的目标就是提升10B左右模型的推理能力。该工作的核心创新点在于使用对话的方式降低了模型解决推理问题的难度，并通过PPO训练了一个用于过程监督的强化学习模型进一步提升模型的推理能力。具体做法是，让小模型分别扮演Decomposer和Solver两个角色，对于Decomposer而言，当用户输入了一个复杂问题后，它只需要将问题拆解为一系列子问题，Solver的目标则是回答这一系列子问题。他们提出了三种不同的问题拆解方式，实现了通过对话的方式逐步引导模型生成整个复杂CoT的过程，有效降低了任务难度，从而更适合10B左右的模型进行求解。在此基础上，又提出了一个使用PPO训练的强化学习模型利用子问题的答案作为中间监督信号，更细粒度地优化了模型的推理路径，进一步提升了模型的推理性能。
最后，韩程程展示了对话式CoT在多个算术推理数据集上的实验：除了在Flan-T5这种Encoder-Decoder架构的模型上进行了实验之外，还在LLaMA这种Decoder-only的模型架构上进行了实验。实验结果证明对话式CoT在多种不同的模型架构上都有效提升了模型的推理能力，显著优于目前的其他方法。
王宇

Source Code Summarization:

From General To 

Project Specific
在本次报告中，王宇首先介绍了”源代码注释生成（CSG）”模型的相关背景知识，包括该问题的定义以及模型的输入等。接着，他介绍了一些在通用场景下用于代码注释生成（GCS）的SOTA模型。报告指出，当前大部分已有的CSG工作大多采用单模态模型，因此很难同时兼顾文本输出质量以及代码关键信息的保留。为了解决这个问题，王宇提出了一种多模态模型Gypsum。这个模型使用了两个编码器和一个解码器。为了更好地捕捉原始代码的结构信息，图的编码器部分通过特定规则将语法树构建成连通图，并将其输入到图注意力网络（GAT）中，从而获得结构化的节点表征。此外，文本编码器部分则利用了CodeBERT这一代码预训练模型。解码器通过对两部分表征的融合，增强了其对代码文本和结构信息捕获的能力，并提升了输出文本的质量。
随后，王宇提到，同一个项目下的代码和注释很可能遵循统一的规范和风格。因此，利用项目内部已有的信息来增强未知注释的生成是一个值得研究的方向。他介绍了目前已有的两个基于项目的代码注释生成（PCS）模型。由于应用场景的不同，这两个模型生成的注释质量并不理想。为了解决这个问题，王宇提出了一种基于项目特征的模型CSWPS。该模型在第一阶段结合了有监督的分类与无监督的对比学习，以挖掘不同项目内部注释的特有信息。在第二阶段，该模型利用项目信息和代码生成的分布来采样第一阶段生成的信息，并将其融入到解码器中，以增强模型对项目内部已有代码和注释的关注。实验结果表明，CSWPS能够提升目前已有的大部分CSG模型的表现。
最后，王宇指出了在大模型领域进行CS任务所面临的一些挑战，主要包括缺乏高质量的微调数据集以及缺乏合理且公正的评价指标等问题。
活动总结 SUMMARY

本次学术沙龙由华东师范大学研究生院主办、数据科学与工程学院和数据科学与工程学院研究生会联合承办。四位讲者的报告分享了大型语言模型的应用与目前所面临的挑战，同学们积极参与讨论，分享经验和观点。通过思想碰撞和学术交流，同学们获得了丰富的知识和启发，这也是数据学院本次学术沙龙的意义所在。
华东师范大学数据科学与工程学院


